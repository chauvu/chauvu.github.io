{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12674039",
   "metadata": {},
   "source": [
    "# Segmentation of white matter lesions from MRI with Faster RCNN\n",
    "\n",
    "White matter lesions (also called white matter hyperintensities, silent cerebral infarcts, silent strokes, etc.) typically represent as bright spots on MRI T2 FLAIR images. A current active area of research is automatic identification and segmentation of these silent infarcts to derive positions, volumes and stereological features. This segmentation task is suited for a Region-based CNN approach. If a precise segmentation of the lesion is needed, then Mask RCNN is the appropriate approach.\n",
    "\n",
    "In this project, since my previous project has proposed a seed-based semi-automatic segmentation approach based on Canny edge detection (cited in this [ref](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6192027/)), to avoid unnecessary training, I have chosen to apply **Faster RCNN** instead of Mask RCNN. Faster RCNN will only yield bounding boxes for each lesion instead of the segmentation mask. Subsequently, we can feed these bounding boxes into the semi-automatic segmentation engine to yield lesion masks.\n",
    "\n",
    "Instead of implementing the network from scratch, I will use the **IceVision** library (https://airctic.com/0.11.0/) built upon the FastAI framework to train and generate predictions for the white matter lesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cae199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icevision\n",
    "from icevision.all import *\n",
    "from icevision.models.torchvision import faster_rcnn\n",
    "from icevision.models.checkpoint import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastai\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab82f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_trained = True # load model instead of training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e382ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class MyParser(Parser):\n",
      "    def __init__(self, template_record):\n",
      "        super().__init__(template_record=template_record)\n",
      "    def __iter__(self) -> Any:\n",
      "    def __len__(self) -> int:\n",
      "    def record_id(self, o: Any) -> Hashable:\n",
      "    def parse_fields(self, o: Any, record: BaseRecord, is_new: bool):\n",
      "        record.set_filepath(<Union[str, Path]>)\n",
      "        record.set_img_size(<ImgSize>)\n",
      "        record.detection.set_class_map(<ClassMap>)\n",
      "        record.detection.add_labels(<Sequence[Hashable]>)\n",
      "        record.detection.add_bboxes(<Sequence[BBox]>)\n"
     ]
    }
   ],
   "source": [
    "data_root = '/Users/chauvu/Documents/Chau/DataScience/Proj_Lesions_RCNN/lesions/'\n",
    "data_csv = os.path.join(data_root, 'bbox.csv')\n",
    "data_info = pd.read_csv(data_csv, header=0)\n",
    "\n",
    "class_map_list = data_info['type'].unique().tolist()\n",
    "class_map = ClassMap(class_map_list)\n",
    "\n",
    "data_dir = Path(data_root)\n",
    "template_record = ObjectDetectionRecord()\n",
    "Parser.generate_template(template_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89f779",
   "metadata": {},
   "source": [
    "A **Parser** class is defined in order to load training and testing data into the appropriate format for `icevision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0020f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionParser(Parser):\n",
    "\tdef __init__(self, template_record, data_dir):\n",
    "\t\tsuper().__init__(template_record=template_record)\n",
    "\n",
    "\t\tself.data_dir = data_dir\n",
    "\t\tself.df = pd.read_csv(data_dir/'bbox.csv', header=0)\n",
    "\t\tself.class_map = ClassMap(self.df['type'].unique().tolist())\n",
    "\n",
    "\tdef __iter__(self) -> Any:\n",
    "\t\tfor o in self.df.itertuples():\n",
    "\t\t\tyield o\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.df)\n",
    "\n",
    "\tdef record_id(self, o) -> Hashable:\n",
    "\t\treturn o.image_id\n",
    "\n",
    "\tdef parse_fields(self, o, record, is_new):\n",
    "\t\tif is_new:\n",
    "\t\t\tfilepath = self.data_dir / 'images' / f'{o.image_id}.jpg' \n",
    "\t\t\trecord.set_filepath(filepath)\n",
    "\t\t\trecord.set_img_size(ImgSize(width = 30, height = 30))\n",
    "\t\t\trecord.detection.set_class_map(self.class_map)\n",
    "\t\trecord.detection.add_bboxes([BBox.from_xyxy(o.xmin, o.ymin, o.xmax, o.ymax)])\n",
    "\t\trecord.detection.add_labels([o.type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72cdaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LesionParser(template_record, data_dir) \n",
    "dsplit = icevision.data.RandomSplitter([0.8,0.1,0.1], seed=123)\n",
    "train_records, valid_records, test_records = parser.parse(data_splitter=dsplit, show_pbar=False, autofix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770e69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_records(train_records[0:2], ncols=2, display_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715906c",
   "metadata": {},
   "source": [
    "**Data augmentation** is performed on the training set, including shifting, scaling, rotating and cropping. The test set is not augmented. Both datasets are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2ea1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "presize = 512\n",
    "size = 384\n",
    "shift_scale_rotate = tfms.A.ShiftScaleRotate(rotate_limit=10)\n",
    "crop_fn = partial(tfms.A.RandomSizedCrop, min_max_height=(size // 2, size), p=0.5)\n",
    "train_tfms = tfms.A.Adapter(\n",
    "    [\n",
    "        *tfms.A.aug_tfms(\n",
    "            size=size,\n",
    "            presize=presize,\n",
    "            shift_scale_rotate=shift_scale_rotate,\n",
    "            crop_fn=crop_fn,\n",
    "        ),\n",
    "        tfms.A.Normalize(),\n",
    "    ]\n",
    ")\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=size), tfms.A.Normalize()])\n",
    "test_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=size), tfms.A.Normalize()])\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)\n",
    "test_ds = Dataset(test_records, test_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338450ee",
   "metadata": {},
   "source": [
    "As stated previously, I will use **Faster RCNN** model from the IceVision library. I will be using the ResNet50 as the backbone for the CNN classification. The checkpoint `chkpt_lesions.pth` is available for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93fc8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /Users/chauvu/Documents/Chau/DataScience/Proj_Lesions_RCNN/lesions/chkpt_lesions.pth\n"
     ]
    }
   ],
   "source": [
    "model_type = faster_rcnn\n",
    "backbone = model_type.backbones.resnet50_fpn\n",
    "model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map)) \n",
    "\n",
    "checkpoint_path = data_dir / 'chkpt_lesions.pth'\n",
    "if already_trained:\n",
    "\tmodel = model_from_checkpoint(str(checkpoint_path), \n",
    "\t\t\t\t\t\t\t\t\t    model_name='torchvision.faster_rcnn',\n",
    "\t\t\t\t\t\t\t\t\t    backbone_name='resnet50_fpn',\n",
    "\t\t\t\t\t\t\t\t\t    )\n",
    "\tmodel = model['model']\n",
    "    \n",
    "train_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=0, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=0, shuffle=False)\n",
    "test_dl = model_type.valid_dl(test_ds, batch_size=16, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c20d5",
   "metadata": {},
   "source": [
    "Training is performed for 10 epochs. Since the data is so large and training is performed on a CPU, it took 2 days to complete. The model checkpoint is saved, here are the training losses and COCOMetrics for the 10 epochs.\n",
    "\n",
    "epoch     train_loss  valid_loss  COCOMetric   \n",
    "0         0.305333    0.292251    0.032314                         \n",
    "1         0.307596    0.301169    0.050098                        \n",
    "2         0.286604    0.293986    0.050614                        \n",
    "3         0.298923    0.296777    0.101636                        \n",
    "4         0.307370    0.286497    0.151044                         \n",
    "5         0.280956    0.276258    0.182553                         \n",
    "6         0.284154    0.275480    0.204247                          \n",
    "7         0.258887    0.265800    0.222916                          \n",
    "8         0.279240    0.264212    0.227343                         \n",
    "9         0.278910    0.262303    0.236614  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f310d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)\n",
    "\n",
    "if not already_trained:\n",
    "\tlearn.freeze()\n",
    "\tsuggested_lr = learn.lr_find()\n",
    "\tcbs = [fastai.callback.tracker.SaveModelCallback(every_epoch=1)]\n",
    "\tlearn.fine_tune(10, suggested_lr.valley, cbs=cbs)\n",
    "\n",
    "\t# SAVE CHECKPOINT\n",
    "\tsave_icevision_checkpoint(model, \n",
    "                        model_name='torchvision.faster_rcnn', \n",
    "                        backbone_name='resnet50_fpn',\n",
    "                        classes = class_map_list, \n",
    "                        filename = str(checkpoint_path),\n",
    "                        meta = {'icevision_version': '0.11.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "518590e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>COCOMetric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305333</td>\n",
       "      <td>0.292251</td>\n",
       "      <td>0.032314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.050098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.286604</td>\n",
       "      <td>0.293986</td>\n",
       "      <td>0.050614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.298923</td>\n",
       "      <td>0.296777</td>\n",
       "      <td>0.101636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.307370</td>\n",
       "      <td>0.286497</td>\n",
       "      <td>0.151044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.280956</td>\n",
       "      <td>0.276258</td>\n",
       "      <td>0.182553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.275480</td>\n",
       "      <td>0.204247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.222916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.279240</td>\n",
       "      <td>0.264212</td>\n",
       "      <td>0.227343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.278910</td>\n",
       "      <td>0.262303</td>\n",
       "      <td>0.236614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  valid_loss  COCOMetric\n",
       "0    0.0    0.305333    0.292251    0.032314\n",
       "1    1.0    0.307596    0.301169    0.050098\n",
       "2    2.0    0.286604    0.293986    0.050614\n",
       "3    3.0    0.298923    0.296777    0.101636\n",
       "4    4.0    0.307370    0.286497    0.151044\n",
       "5    5.0    0.280956    0.276258    0.182553\n",
       "6    6.0    0.284154    0.275480    0.204247\n",
       "7    7.0    0.258887    0.265800    0.222916\n",
       "8    8.0    0.279240    0.264212    0.227343\n",
       "9    9.0    0.278910    0.262303    0.236614"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_metrics = pd.DataFrame(columns=['epoch', 'train_loss', 'valid_loss', 'COCOMetric'])\n",
    "training_metrics = training_metrics.append({'epoch': 0, 'train_loss': 0.305333, 'valid_loss': 0.292251, 'COCOMetric': 0.032314}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 1, 'train_loss': 0.307596, 'valid_loss': 0.301169, 'COCOMetric': 0.050098}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 2, 'train_loss': 0.286604, 'valid_loss': 0.293986, 'COCOMetric': 0.050614}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 3, 'train_loss': 0.298923, 'valid_loss': 0.296777, 'COCOMetric': 0.101636}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 4, 'train_loss': 0.307370, 'valid_loss': 0.286497, 'COCOMetric': 0.151044}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 5, 'train_loss': 0.280956, 'valid_loss': 0.276258, 'COCOMetric': 0.182553}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 6, 'train_loss': 0.284154, 'valid_loss': 0.275480, 'COCOMetric': 0.204247}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 7, 'train_loss': 0.258887, 'valid_loss': 0.265800, 'COCOMetric': 0.222916}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 8, 'train_loss': 0.279240, 'valid_loss': 0.264212, 'COCOMetric': 0.227343}, ignore_index=True)\n",
    "training_metrics = training_metrics.append({'epoch': 9, 'train_loss': 0.278910, 'valid_loss': 0.262303, 'COCOMetric': 0.236614}, ignore_index=True)\n",
    "training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29c28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dl = model_type.infer_dl(test_ds, batch_size=16)\n",
    "if not already_trained:\n",
    "\tpreds = model_type.predict_from_dl(model, infer_dl, keep_images=True)\n",
    "\twith open(data_dir / 'preds_lesions.pkl', 'wb') as f:\n",
    "\t\tpickle.dump(preds, f)\n",
    "else:\n",
    "\twith open(data_dir / 'preds_lesions.pkl', 'rb') as f:\n",
    "\t\tpreds = pickle.load(f)\n",
    "\n",
    "# show_preds(preds=preds[7:9])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0c7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6393224606541984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chauvu/Documents/Chau/DataScience/Proj_Lesions_RCNN/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/chauvu/Documents/Chau/DataScience/Proj_Lesions_RCNN/env/lib/python3.9/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "preds_gt1 = [p for p in preds if len(p.ground_truth.as_dict()['detection']['bboxes'])==1]\n",
    "\n",
    "preds_dsc = []\n",
    "for p in preds_gt1:\n",
    "\tp_dsc = []\n",
    "\tp_gt = p.ground_truth.as_dict()['detection']['bboxes'][0]\n",
    "\tp_prs = p.pred.as_dict()['detection']['bboxes']\n",
    "\tfor p_pr in p_prs:\n",
    "\t\tx_left = max(p_gt.xmin, p_pr.xmin)\n",
    "\t\ty_top = max(p_gt.ymin, p_pr.ymin)\n",
    "\t\tx_right = min(p_gt.xmax, p_pr.xmax)\n",
    "\t\ty_bottom = min(p_gt.ymax, p_pr.ymax)\n",
    "\n",
    "\t\tif x_right < x_left or y_bottom < y_top:\n",
    "\t\t\ttp = 0\n",
    "\t\telse:\n",
    "\t\t\ttp = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "\t\tfp = (p_pr.xmax - p_pr.xmin) * (p_pr.ymax - p_pr.ymin) - tp\n",
    "\t\tfn = (p_gt.xmax - p_gt.xmin) * (p_gt.ymax - p_gt.ymin) - tp\n",
    "\t\tdsc = 2*tp / (2*tp + fp + fn)\n",
    "\t\tp_dsc.append(dsc)\n",
    "\tpreds_dsc.append(np.mean(p_dsc))\n",
    "preds_dsc = [p for p in preds_dsc if not np.isnan(p)]\n",
    "\n",
    "print(np.mean(preds_dsc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff4c6e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The mean Dice Similarity Coefficient is 0.64 for the bounding boxes. This is very good since we are not interested in the actual area of the bounding boxes, but rather it relative location to the lesion. After getting the bounding boxes, we can select a central voxel within the bounding box as the seed into the semi-automatic lesion segmentation algorithm. Therefore, a 0.64 Dice score is very good because it proves that these predicted bounding boxes do cover part of the lesions, so choosing a seed within the boxes are reasonable to generate lesion masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd3d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
