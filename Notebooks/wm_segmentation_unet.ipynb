{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19292474",
   "metadata": {},
   "source": [
    "# WM Segmentation using U-Net\n",
    "In this project, I will use MRI T1-weighted images to segmentation white matter (WM) from other tissues in the brain, such as grey matter and cerebrospinal fluid. There are many preprocessing toolboxes that perform GM/WM segmentation, including [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki), [SPM](https://www.fil.ion.ucl.ac.uk/spm/) and [BrainSuite](http://brainsuite.org/). This problem has also frequently been tackled using deep learning, with [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/), which is the convolutional neural network for biomedical segmentation.\n",
    "\n",
    "In this script, I will implement this U-Net using tensorflow and calculate the Dice Similarity Coefficient on the test set white matter segmentations. Ground truth white matter masks are generated using BrainSuite, with voxels of > 50% probability of being within white matter. Instead of training the network using the full image, I will use 64x64 patches extracted from the MRI dataset. No data augmentation is performed to simplify this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d865386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction import image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e169d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "patch_size = 64\n",
    "already_generated = True\n",
    "\n",
    "root_dir = 'Brain_T1.nosync/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874521b",
   "metadata": {},
   "source": [
    "The training and testing image patches have already been extracted, split and saved in the home folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b160d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_dir+'t1_patches_train2.npy', 'rb') as f:\n",
    "\tt1_patches_train = np.load(f)\n",
    "with open(root_dir+'t1_patches_test2.npy', 'rb') as f:\n",
    "\tt1_patches_test = np.load(f)\n",
    "with open(root_dir+'wm_patches_train2.npy', 'rb') as f:\n",
    "\twm_patches_train = np.load(f)\n",
    "with open(root_dir+'wm_patches_test2.npy', 'rb') as f:\n",
    "\twm_patches_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d400475",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(t1_patches_train)\n",
    "len_test = len(t1_patches_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09223bb",
   "metadata": {},
   "source": [
    "### U-Net\n",
    "I will implement a U-Net architecture, in which regional and global features are trained using the 2D convolution layer `Conv2D` and aggregated to generate the white matter probability map. I will specify the learning rate as 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02c5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape=(64,64,1), dropout_rate=0.20, kernel_size=(3,3), optimizer='adam',\n",
    "\t\t\t\tdense_params=64, maxpool_size=(2,2), activation='relu'):\n",
    "\tinput_image = Input(input_shape)\n",
    "\tc1 = Conv2D(16, kernel_size=kernel_size, activation=activation, padding='same')(input_image)\t\n",
    "\tc1 = Conv2D(16, kernel_size=kernel_size, activation=activation, padding='same')(c1)\t\n",
    "\tp1 = MaxPooling2D(pool_size=maxpool_size)(c1)\n",
    "\tp1 = Dropout(dropout_rate)(p1)\n",
    "\n",
    "\tc2 = Conv2D(32, kernel_size=kernel_size, activation=activation, padding='same')(p1)\t\n",
    "\tc2 = Conv2D(32, kernel_size=kernel_size, activation=activation, padding='same')(c2)\t\n",
    "\tp2 = MaxPooling2D(pool_size=maxpool_size)(c2)\n",
    "\tp2 = Dropout(dropout_rate)(p2)\n",
    "\n",
    "\tc3 = Conv2D(64, kernel_size=kernel_size, activation=activation, padding='same')(p2)\n",
    "\tc3 = Conv2D(64, kernel_size=kernel_size, activation=activation, padding='same')(c3)\n",
    "\n",
    "\tu4 = Conv2DTranspose(32, kernel_size=(2,2), strides=maxpool_size)(c3)\n",
    "\tu4 = Concatenate(axis=3)([u4, c2])\n",
    "\tu4 = Dropout(dropout_rate)(u4)\n",
    "\tc4 = Conv2D(32, kernel_size=kernel_size, activation=activation, padding='same')(u4)\n",
    "\tc4 = Conv2D(32, kernel_size=kernel_size, activation=activation, padding='same')(c4)\n",
    "\n",
    "\tu5 = Conv2DTranspose(16, kernel_size=(2,2), strides=maxpool_size)(c4)\n",
    "\tu4 = Concatenate(axis=3)([u5, c1])\n",
    "\tu5 = Dropout(dropout_rate)(u5)\n",
    "\tc5 = Conv2D(16, kernel_size=kernel_size, activation=activation, padding='same')(u5)\n",
    "\tc5 = Conv2D(16, kernel_size=kernel_size, activation=activation, padding='same')(c5)\n",
    "\n",
    "\toutput_image = Conv2D(1, kernel_size=(1,1), activation='sigmoid')(c5)\n",
    "\tmodel = Model(inputs=input_image, outputs=output_image)\n",
    "\tmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5407f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = unet_model(optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c19dc",
   "metadata": {},
   "source": [
    "Here, I will train the U-Net for 10 epochs. I have trained this network offline and saved the checkpoint for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f2c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not already_generated:\n",
    "    filepath=\"checkpoints.nosync/unet-adam001-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = unet.fit(x=t1_patches_train, y=wm_patches_train, epochs=10, batch_size=128, callbacks=callbacks_list)\n",
    "else:\n",
    "    unet.load_weights('checkpoints.nosync/unet-adam001-10-0.0897.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a0a08",
   "metadata": {},
   "source": [
    "### White Matter Masks\n",
    "I will generate the white matter masks on the T1 MRI patches of the test set. Since the output of the U-Net is the probably map (after sigmoid activation function) of whether a voxel belongs in the white matter or not, I will consider voxels > 50% white matter to be within the mask. (This is the same 50% threshold as when the ground truth masks are generated from BrainSuite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdef7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = unet.predict(t1_patches_test)\n",
    "preds_reshape = preds.squeeze() > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e5919",
   "metadata": {},
   "source": [
    "Due to HIPPA, I am unable to show the results of the segmentation masks side-by-side with the ground truth masks. However, from our predictions, we can calculate the Dice Similarity Coefficient (DSC), which is the score in the [0,1] range of how well the segmented masks matched the ground truth. The final DSC is 0.94, which is a very high result for segmentation, which proves that the white matter segmentation task can be learned very efficiently (after only 10 epochs) using a simple U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e71bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942418467133304\n"
     ]
    }
   ],
   "source": [
    "dsc = np.empty(len_test)\n",
    "for index in range(len_test):\n",
    "\tlabel = wm_patches_test[index,:,:]\n",
    "\tpred = preds_reshape[index,:,:]\n",
    "\ttp = np.sum(label * pred)\n",
    "\tfp = np.sum((label==0) * pred)\n",
    "\tfn = np.sum(label * (pred==0))\n",
    "\tdsc[index] = (2*tp) / (2*tp + fp + fn)\n",
    "print(np.mean(dsc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff57d9",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this work, we use a U-Net neural network to perform white matter segmentation on T1-weighted MRI images. The resulting Dice Similarity Coefficient is 0.94 on the test set, which is a large improvement compared to the use of random forest classifier on each voxel (0.75 Dice Similarity, [link](https://github.com/chauvu/chauvu.github.io/blob/main/Notebooks/wm_segmentation_randomforest.ipynb)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6250859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
